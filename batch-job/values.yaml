# Default values for batch-job.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: gitlab.planetrover.ca:5050/sequoiadp/batch-job
  pullPolicy: IfNotPresent
  # Overrides the image tag whose default is the chart appVersion.
  tag: "latest"

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

s3:
  endpoint: ""
  secret: ""
  bucketName: ""

sparkEventLogDir: ""

sparkJob:
  namespace: "default"
  sparkVersion: "3.0.2"
  image: "gitlab.planetrover.ca:5050/sequoiadp/spark:latest"
  # list of strings
  imagePullSecrets: []
  imagePullPolicy: IfNotPresent
  serviceAccount: spark
  restartPolicy:
    type: OnFailure
    onFailureRetries: 3
    onFailureRetryInterval: 10
    onSubmissionFailureRetries: 3
    onSubmissionFailureRetryInterval: 10
  sparkConf:
    spark.jars.ivy:                                          /tmp/.ivy
    spark.sql.extensions:                                    io.delta.sql.DeltaSparkSessionExtension
    spark.sql.catalog.spark_catalog:                         org.apache.spark.sql.delta.catalog.DeltaCatalog
    spark.delta.logStore.class:                              org.apache.spark.sql.delta.storage.LocalLogStore
    spark.sql.warehouse.dir:                                 alluxio://alluxio-master-0:19998/spark-warehouse/
    spark.eventLog.enabled:                                  "true"
    spark.eventLog.dir:                                      alluxio://alluxio-master-0:19998/spark-logs/
    spark.hadoop.fs.s3a.endpoint:                            192.168.6.97:8002
    spark.hadoop.fs.s3a.access.key:                          ABCDEFGHIJKLMNOPQRST
    spark.hadoop.fs.s3a.secret.key:                          abcdefghijklmnopqrstuvwxyz0123456789ABCD
    spark.hadoop.fs.s3a.impl:                                org.apache.hadoop.fs.s3a.S3AFileSystem
    spark.hadoop.fs.s3a.connection.ssl.enabled:              "false"
    spark.ui.prometheus.enabled:                             "true"
  metrics:
    enabled: "true"
  driver:
    javaOptions: -Dalluxio.master.rpc.addresses=alluxio-master-0:19998
  executor:
    javaOptions: -Dalluxio.master.rpc.addresses=alluxio-master-0:19998

rbac:
  create: true

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: "batch-job"

podAnnotations: {}

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

service:
  type: ClusterIP
  port: 8888

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

autoscaling:
  enabled: false
  minReplicas: 1
  maxReplicas: 100
  targetCPUUtilizationPercentage: 80
  # targetMemoryUtilizationPercentage: 80

nodeSelector: {}

tolerations: []

affinity: {}
